{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5cea389-11ef-4404-8d4a-38688aa16f8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ðŸ§® Generic Managed Tables Audit Notebook (Databricks)\n",
    "\n",
    "**Purpose**: Compare two managed tables and produce a reusable audit with:\n",
    "\n",
    "- Schema parity (names, types, nullability)\n",
    "- Row coverage (counts, missing keys in either side)\n",
    "- Key integrity (duplicate keys)\n",
    "- Value consistency (per-column mismatches with tolerances)\n",
    "- Column statistics (null %, distincts, min/max)\n",
    "- Canonical hash check (optional)\n",
    "- Standardized audit logging (summary + detailed diffs)\n",
    "- Threshold-based PASS/WARN/FAIL + optional job fail\n",
    "\n",
    "**How to use**:\n",
    "1. Set the widgets below (or pass them via Job task parameters).\n",
    "2. Run cells top to bottom.\n",
    "3. Check the final summary and diffs.\n",
    "\n",
    "**Author**: Generated for Raj (Data Engineer) â€” plug-and-play across your datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7505f304-f982-4b79-a60c-a6053e8ab406",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 0) Configuration Widgets\n",
    "Provide table names and options. Keys/exclude are comma-separated. Tolerances are JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f58251c-0200-4fdc-9b6d-858242c64898",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from functools import reduce\n",
    "from datetime import datetime\n",
    "import operator\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Ensure widgets exist (idempotent)\n",
    "try:\n",
    "    # Required\n",
    "    dbutils.widgets.text(\"catalog\", \"kr_payment_nonprod\")\n",
    "    # Required\n",
    "    dbutils.widgets.text(\"source_table\", \"kr_payment_nonprod.tlog_dev.tlog_check_declines_stg\")\n",
    "    dbutils.widgets.text(\"target_table\", \"kr_payment_nonprod.tlog_dev.tlog_check_declines_data\")\n",
    "\n",
    "    # Keys (choose one approach)\n",
    "    dbutils.widgets.text(\"key_map_json\", \"{}\")  # e.g. {\"order_id\":\"id\",\"tenant_id\":\"tenant\"}\n",
    "    dbutils.widgets.text(\"key_columns_source\", \"\")  # fallback, comma-separated\n",
    "    dbutils.widgets.text(\"key_columns_target\", \"\")  # fallback, comma-separated\n",
    "\n",
    "    # Excludes (separate per side)\n",
    "    dbutils.widgets.text(\"exclude_columns_source\", \"_ingest_ts,_load_id\")\n",
    "    dbutils.widgets.text(\"exclude_columns_target\", \"_ingest_ts,_load_id\")\n",
    "\n",
    "    # Compare mapping (optional): src_col -> tgt_col when names differ; same-name cols auto-inferred otherwise\n",
    "    dbutils.widgets.text(\"compare_map_json\", \"{}\")\n",
    "\n",
    "    # Filters and partitions\n",
    "    dbutils.widgets.text(\"partition_column\", \"\")\n",
    "    dbutils.widgets.text(\"partition_values\", \"\")\n",
    "    dbutils.widgets.text(\"filter_condition_source\", \"\")\n",
    "    dbutils.widgets.text(\"filter_condition_target\", \"\")\n",
    "\n",
    "    # Tolerances and options\n",
    "    dbutils.widgets.text(\"tolerance_map_json\", \"{}\")  # keyed by src or tgt col name\n",
    "    dbutils.widgets.dropdown(\"hash_check\", \"true\", [\"true\", \"false\"], \"hash_check\")\n",
    "    dbutils.widgets.text(\"audit_database\", \"_sandbox_dev\")\n",
    "    dbutils.widgets.text(\"run_id\", \"\")\n",
    "\n",
    "    # Alerts / thresholds\n",
    "    dbutils.widgets.text(\"alert_missing_row_threshold\", \"0\")\n",
    "    dbutils.widgets.text(\"alert_mismatch_ratio_threshold\", \"0.001\")\n",
    "    dbutils.widgets.dropdown(\"fail_on_threshold_breach\", \"false\", [\"true\", \"false\"], \"fail_on_threshold_breach\")\n",
    "except NameError:\n",
    "    # If not running on Databricks (unit testing), create shims\n",
    "    class DBUtilsShim:\n",
    "        class Widgets:\n",
    "            store = {}\n",
    "            def text(self, name, default):\n",
    "                self.store[name] = default\n",
    "            def dropdown(self, name, default, choices, label=None):\n",
    "                self.store[name] = default\n",
    "            def get(self, name):\n",
    "                return self.store.get(name, \"\")\n",
    "        widgets = Widgets()\n",
    "    dbutils = DBUtilsShim()\n",
    "\n",
    "# Read widget values\n",
    "SOURCE_TABLE = dbutils.widgets.get(\"source_table\")\n",
    "TARGET_TABLE = dbutils.widgets.get(\"target_table\")\n",
    "\n",
    "KEY_MAP = json.loads(dbutils.widgets.get(\"key_map_json\") or \"{}\")\n",
    "KEY_SRC_LIST = [c.strip() for c in (dbutils.widgets.get(\"key_columns_source\") or \"\").split(\",\") if c.strip()]\n",
    "KEY_TGT_LIST = [c.strip() for c in (dbutils.widgets.get(\"key_columns_target\") or \"\").split(\",\") if c.strip()]\n",
    "\n",
    "EXCL_SRC = [c.strip() for c in (dbutils.widgets.get(\"exclude_columns_source\") or \"\").split(\",\") if c.strip()]\n",
    "EXCL_TGT = [c.strip() for c in (dbutils.widgets.get(\"exclude_columns_target\") or \"\").split(\",\") if c.strip()]\n",
    "\n",
    "COMPARE_MAP = json.loads(dbutils.widgets.get(\"compare_map_json\") or \"{}\")  # src -> tgt\n",
    "\n",
    "PARTITION_COL = (dbutils.widgets.get(\"partition_column\") or \"\").strip()\n",
    "PARTITION_VALUES = [v.strip() for v in (dbutils.widgets.get(\"partition_values\") or \"\").split(\",\") if v.strip()]\n",
    "FILTER_SRC = (dbutils.widgets.get(\"filter_condition_source\") or \"\").strip()\n",
    "FILTER_TGT = (dbutils.widgets.get(\"filter_condition_target\") or \"\").strip()\n",
    "\n",
    "TOL_MAP = json.loads(dbutils.widgets.get(\"tolerance_map_json\") or \"{}\")\n",
    "HASH_CHECK = ((dbutils.widgets.get(\"hash_check\") or \"true\").lower() == \"true\")\n",
    "CATALOG_NAME = dbutils.widgets.get(\"catalog\") or \"main\"\n",
    "AUDIT_DB = dbutils.widgets.get(\"audit_database\") or \"_sandbox_dev\"\n",
    "RUN_ID = dbutils.widgets.get(\"run_id\") or f\"run_{int(time.time())}\"\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "ALERT_MISSING_THRESHOLD = int(float(dbutils.widgets.get(\"alert_missing_row_threshold\") or \"0\"))\n",
    "ALERT_MISMATCH_RATIO_THRESHOLD = float(dbutils.widgets.get(\"alert_mismatch_ratio_threshold\") or \"0.001\")\n",
    "FAIL_ON_BREACH = ((dbutils.widgets.get(\"fail_on_threshold_breach\") or \"false\").lower() == \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ef4d424-0594-44ee-a659-1bd717607297",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1) Utilities\n",
    "Helper functions for normalization, schema comparison, logging, and diffs generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "855a2084-20af-4466-af18-a8d933107e27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def normalize_string(col):\n",
    "    return F.lower(F.trim(F.col(col).cast(\"string\")))\n",
    "\n",
    "\n",
    "def apply_filters(df, filter_expr: str):\n",
    "    return df.filter(F.expr(filter_expr)) if filter_expr else df\n",
    "\n",
    "\n",
    "def parse_key_map(src_df, tgt_df):\n",
    "    \"\"\"Build key mapping source->target from JSON or from paired lists.\"\"\"\n",
    "    if KEY_MAP:\n",
    "        return KEY_MAP\n",
    "    if KEY_SRC_LIST and KEY_TGT_LIST and len(KEY_SRC_LIST) == len(KEY_TGT_LIST):\n",
    "        return dict(zip(KEY_SRC_LIST, KEY_TGT_LIST))\n",
    "    raise ValueError(\"Key mapping not provided. Set key_map_json or paired key_columns_source/target with equal length.\")\n",
    "\n",
    "\n",
    "def is_numeric_type(dt: T.DataType) -> bool:\n",
    "    return isinstance(dt, (T.ByteType, T.ShortType, T.IntegerType, T.LongType, T.FloatType, T.DoubleType, T.DecimalType))\n",
    "\n",
    "\n",
    "def get_tolerance_for(src_col: str, tgt_col: str):\n",
    "    # lookup tolerance by src name first, else by target name\n",
    "    tol = TOL_MAP.get(src_col) or TOL_MAP.get(tgt_col)\n",
    "    return tol\n",
    "\n",
    "\n",
    "def create_audit_tables():\n",
    "    spark.sql(f\"CREATE DATABASE IF NOT EXISTS {CATALOG_NAME}\")\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {CATALOG_NAME}.{AUDIT_DB}.audit_results (\n",
    "          run_id STRING,\n",
    "          run_ts TIMESTAMP,\n",
    "          source_table STRING,\n",
    "          target_table STRING,\n",
    "          partition_value STRING,\n",
    "          filter_source STRING,\n",
    "          filter_target STRING,\n",
    "          metric STRING,\n",
    "          metric_value DOUBLE,\n",
    "          threshold DOUBLE,\n",
    "          status STRING,\n",
    "          notes STRING\n",
    "        ) USING DELTA\n",
    "    \"\"\")\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {CATALOG_NAME}.{AUDIT_DB}.audit_diffs (\n",
    "          run_id STRING,\n",
    "          diff_type STRING,\n",
    "          key_src_json STRING,\n",
    "          key_tgt_json STRING,\n",
    "          partition_value STRING,\n",
    "          filter_source STRING,\n",
    "          filter_target STRING,\n",
    "          col_name STRING,\n",
    "          src_value STRING,\n",
    "          tgt_value STRING\n",
    "        ) USING DELTA\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "def log_summary(rows):\n",
    "    schema = T.StructType([\n",
    "        T.StructField(\"run_id\", T.StringType(), False),\n",
    "        T.StructField(\"run_ts\", T.TimestampType(), False),\n",
    "        T.StructField(\"source_table\", T.StringType(), False),\n",
    "        T.StructField(\"target_table\", T.StringType(), False),\n",
    "        T.StructField(\"partition_value\", T.StringType(), True),\n",
    "        T.StructField(\"filter_source\", T.StringType(), True),\n",
    "        T.StructField(\"filter_target\", T.StringType(), True),\n",
    "        T.StructField(\"metric\", T.StringType(), False),\n",
    "        T.StructField(\"metric_value\", T.DoubleType(), True),\n",
    "        T.StructField(\"threshold\", T.DoubleType(), True),\n",
    "        T.StructField(\"status\", T.StringType(), False),\n",
    "        T.StructField(\"notes\", T.StringType(), True),\n",
    "    ])\n",
    "    df = spark.createDataFrame(rows, schema)\n",
    "    df.write.mode(\"append\").saveAsTable(f\"{CATALOG_NAME}.{AUDIT_DB}.audit_results\")\n",
    "\n",
    "\n",
    "def log_diffs(df):\n",
    "    if df is not None:\n",
    "        df.write.mode(\"append\").saveAsTable(f\"{CATALOG_NAME}.{AUDIT_DB}.audit_diffs\")\n",
    "\n",
    "\n",
    "def json_obj_from_cols(prefix: str, cols: list):\n",
    "    parts = [F.concat(F.lit(f'\"{c}\":\"'), F.col(f\"{prefix}{c}\").cast(\"string\"), F.lit('\"')) for c in cols]\n",
    "    return F.concat(F.lit(\"{\"), F.concat_ws(\",\", *parts), F.lit(\"}\")) if parts else F.lit(\"{}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50d20ef0-ce3e-442a-aeb7-4a2bc85ffdad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2) Load, Filter, and Align Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac0ffb15-5c7b-47b0-82dc-3bdec2edc185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create_audit_tables()\n",
    "\n",
    "src_df = spark.table(SOURCE_TABLE)\n",
    "tgt_df = spark.table(TARGET_TABLE)\n",
    "\n",
    "# Apply optional partition pruning\n",
    "if PARTITION_COL and PARTITION_VALUES:\n",
    "    src_df = src_df.filter(F.col(PARTITION_COL).isin(PARTITION_VALUES))\n",
    "    tgt_df = tgt_df.filter(F.col(PARTITION_COL).isin(PARTITION_VALUES))\n",
    "\n",
    "# Apply arbitrary filters\n",
    "src_df = apply_filters(src_df, FILTER_SRC)\n",
    "tgt_df = apply_filters(tgt_df, FILTER_TGT or FILTER_SRC)\n",
    "\n",
    "# Derive key mapping\n",
    "KEY_MAP = parse_key_map(src_df, tgt_df)  # src->tgt\n",
    "KEY_SRC = list(KEY_MAP.keys())\n",
    "KEY_TGT = [KEY_MAP[k] for k in KEY_SRC]\n",
    "\n",
    "# Determine compare pairs (src->tgt)\n",
    "compare_pairs = []\n",
    "if COMPARE_MAP:\n",
    "    for s, t in COMPARE_MAP.items():\n",
    "        if s in src_df.columns and t in tgt_df.columns and (s not in EXCL_SRC) and (t not in EXCL_TGT):\n",
    "            compare_pairs.append((s, t))\n",
    "# Auto-add same-name columns present on both sides, excluding keys & excludes and not already mapped\n",
    "existing_mapped_src = set(s for s, _ in compare_pairs)\n",
    "for col in src_df.columns:\n",
    "    if col in tgt_df.columns        and col not in existing_mapped_src        and col not in KEY_SRC and col not in EXCL_SRC        and col not in KEY_TGT and col not in EXCL_TGT:\n",
    "        compare_pairs.append((col, col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a05152a-f6bf-4cfd-9c33-0d07252204ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3) Schema Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f79cdb7c-9525-4379-b07f-60c4790a4bbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build schema maps\n",
    "s_map = {f.name: (str(f.dataType), f.nullable) for f in src_df.schema.fields}\n",
    "t_map = {f.name: (str(f.dataType), f.nullable) for f in tgt_df.schema.fields}\n",
    "all_cols = sorted(set(s_map.keys()) | set(t_map.keys()))\n",
    "\n",
    "schema_diff_rows = []\n",
    "for c in all_cols:\n",
    "    s = s_map.get(c)\n",
    "    t = t_map.get(c)\n",
    "    if s != t:\n",
    "        schema_diff_rows.append({\n",
    "            \"run_id\": RUN_ID,\n",
    "            \"diff_type\": \"SCHEMA_DIFF\",\n",
    "            \"key_src_json\": \"{}\",\n",
    "            \"key_tgt_json\": \"{}\",\n",
    "            \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None,\n",
    "            \"filter_source\": FILTER_SRC or None,\n",
    "            \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "            \"col_name\": c,\n",
    "            \"src_value\": f\"type={s[0]}, nullable={s[1]}\" if s else None,\n",
    "            \"tgt_value\": f\"type={t[0]}, nullable={t[1]}\" if t else None,\n",
    "        })\n",
    "\n",
    "schema_diff_df = spark.createDataFrame(schema_diff_rows, schema=T.StructType([\n",
    "    T.StructField(\"run_id\", T.StringType(), False),\n",
    "    T.StructField(\"diff_type\", T.StringType(), False),\n",
    "    T.StructField(\"key_src_json\", T.StringType(), False),\n",
    "    T.StructField(\"key_tgt_json\", T.StringType(), False),\n",
    "    T.StructField(\"partition_value\", T.StringType(), True),\n",
    "    T.StructField(\"filter_source\", T.StringType(), True),\n",
    "    T.StructField(\"filter_target\", T.StringType(), True),\n",
    "    T.StructField(\"col_name\", T.StringType(), True),\n",
    "    T.StructField(\"src_value\", T.StringType(), True),\n",
    "    T.StructField(\"tgt_value\", T.StringType(), True),\n",
    "])) if schema_diff_rows else None\n",
    "\n",
    "log_diffs(schema_diff_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4658fd0b-17aa-4021-aa45-bd0b0fd4d91c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4) Row Counts & Duplicate Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26bb4991-5062-44be-a978-cd2b6e90465f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "row_count_src = src_df.count()\n",
    "row_count_tgt = tgt_df.count()\n",
    "\n",
    "src_dups = src_df.groupBy(*[F.col(c) for c in KEY_SRC]).count().filter(F.col(\"count\") > 1).count()\n",
    "tgt_dups = tgt_df.groupBy(*[F.col(c) for c in KEY_TGT]).count().filter(F.col(\"count\") > 1).count()\n",
    "\n",
    "summary_rows = []\n",
    "summary_rows.extend([\n",
    "    {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE, \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None,\n",
    "     \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "     \"metric\": \"row_count_source\", \"metric_value\": float(row_count_src), \"threshold\": None, \"status\": \"INFO\", \"notes\": None},\n",
    "    {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE, \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None,\n",
    "     \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "     \"metric\": \"row_count_target\", \"metric_value\": float(row_count_tgt), \"threshold\": None, \"status\": \"INFO\", \"notes\": None},\n",
    "    {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE, \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None,\n",
    "     \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "     \"metric\": \"duplicate_keys_source\", \"metric_value\": float(src_dups), \"threshold\": 0.0, \"status\": \"FAIL\" if src_dups > 0 else \"PASS\", \"notes\": None},\n",
    "    {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE, \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None,\n",
    "     \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "     \"metric\": \"duplicate_keys_target\", \"metric_value\": float(tgt_dups), \"threshold\": 0.0, \"status\": \"FAIL\" if tgt_dups > 0 else \"PASS\", \"notes\": None},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56c6284c-583e-43f5-a725-cb5123001685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5) Missing Rows (Asymmetric Keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd9b737d-8eb6-4da2-9c4e-5f67dbed318d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "src_keys_df = src_df.select(*[F.col(k).alias(k) for k in KEY_SRC])\n",
    "tgt_keys_df = tgt_df.select(*[F.col(t).alias(s) for s, t in KEY_MAP.items()])\n",
    "\n",
    "missing_in_tgt = src_keys_df.join(tgt_keys_df, on=KEY_SRC, how=\"left_anti\")\n",
    "missing_in_src = tgt_keys_df.join(src_keys_df, on=KEY_SRC, how=\"left_anti\")\n",
    "\n",
    "missing_tgt_count = missing_in_tgt.count()\n",
    "missing_src_count = missing_in_src.count()\n",
    "\n",
    "summary_rows.extend([\n",
    "    {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE, \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None,\n",
    "     \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "     \"metric\": \"missing_in_target\", \"metric_value\": float(missing_tgt_count), \"threshold\": float(ALERT_MISSING_THRESHOLD),\n",
    "     \"status\": \"FAIL\" if missing_tgt_count > ALERT_MISSING_THRESHOLD else (\"WARN\" if missing_tgt_count > 0 else \"PASS\"), \"notes\": None},\n",
    "    {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE, \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None,\n",
    "     \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "     \"metric\": \"missing_in_source\", \"metric_value\": float(missing_src_count), \"threshold\": float(ALERT_MISSING_THRESHOLD),\n",
    "     \"status\": \"FAIL\" if missing_src_count > ALERT_MISSING_THRESHOLD else (\"WARN\" if missing_src_count > 0 else \"PASS\"), \"notes\": None},\n",
    "])\n",
    "\n",
    "# Prepare missing diffs\n",
    "missing_in_tgt_diffs = missing_in_tgt.select(\n",
    "    F.lit(RUN_ID).alias(\"run_id\"),\n",
    "    F.lit(\"MISSING_IN_TARGET\").alias(\"diff_type\"),\n",
    "    json_obj_from_cols(\"\", KEY_SRC).alias(\"key_src_json\"),\n",
    "    json_obj_from_cols(\"\", KEY_SRC).alias(\"key_tgt_json\"),  # same names here (aliased)\n",
    "    F.lit(\",\".join(PARTITION_VALUES) if PARTITION_VALUES else None).alias(\"partition_value\"),\n",
    "    F.lit(FILTER_SRC or None).alias(\"filter_source\"),\n",
    "    F.lit(FILTER_TGT or (FILTER_SRC or None)).alias(\"filter_target\"),\n",
    "    F.lit(None).cast(\"string\").alias(\"col_name\"),\n",
    "    F.lit(None).cast(\"string\").alias(\"src_value\"),\n",
    "    F.lit(None).cast(\"string\").alias(\"tgt_value\")\n",
    ")\n",
    "missing_in_src_diffs = missing_in_src.select(\n",
    "    F.lit(RUN_ID).alias(\"run_id\"),\n",
    "    F.lit(\"MISSING_IN_SOURCE\").alias(\"diff_type\"),\n",
    "    json_obj_from_cols(\"\", KEY_SRC).alias(\"key_src_json\"),\n",
    "    json_obj_from_cols(\"\", KEY_SRC).alias(\"key_tgt_json\"),\n",
    "    F.lit(\",\".join(PARTITION_VALUES) if PARTITION_VALUES else None).alias(\"partition_value\"),\n",
    "    F.lit(FILTER_SRC or None).alias(\"filter_source\"),\n",
    "    F.lit(FILTER_TGT or (FILTER_SRC or None)).alias(\"filter_target\"),\n",
    "    F.lit(None).cast(\"string\").alias(\"col_name\"),\n",
    "    F.lit(None).cast(\"string\").alias(\"src_value\"),\n",
    "    F.lit(None).cast(\"string\").alias(\"tgt_value\")\n",
    ")\n",
    "\n",
    "log_diffs(missing_in_tgt_diffs)\n",
    "log_diffs(missing_in_src_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee5323df-797d-4c03-8f84-219b875d8443",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6) Value Mismatches (With Column Mapping & Tolerances)\n",
    "Value Mismatches (Join & Compare with Tolerances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2cd33db-de78-4d92-ada5-ac3f952b0d62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "s = src_df.alias(\"s\")\n",
    "t = tgt_df.select(*[F.col(tgt).alias(src) for src, tgt in KEY_MAP.items()], *[F.col(c).alias(c) for c in tgt_df.columns if c not in KEY_TGT]).alias(\"t\")\n",
    "\n",
    "joined = s.join(t, on=KEY_SRC, how=\"inner\")\n",
    "\n",
    "# Per-pair mismatch conditions\n",
    "mismatch_conditions = []\n",
    "per_col_diffs = []\n",
    "\n",
    "# For numeric casting decisions\n",
    "src_type_map = dict(src_df.dtypes)  # col -> spark string type\n",
    "tgt_type_map = dict(tgt_df.dtypes)\n",
    "\n",
    "for src_col, tgt_col in compare_pairs:\n",
    "    s_col = F.col(f\"s.{src_col}\")\n",
    "    t_col = F.col(f\"t.{tgt_col if tgt_col in tgt_df.columns else tgt_col}\")\n",
    "\n",
    "    tol = get_tolerance_for(src_col, tgt_col)\n",
    "\n",
    "    # Decide comparison strategy\n",
    "    s_dtype = next((f.dataType for f in src_df.schema.fields if f.name == src_col), None)\n",
    "    t_dtype = next((f.dataType for f in tgt_df.schema.fields if f.name == tgt_col), None)\n",
    "\n",
    "    if is_numeric_type(s_dtype) and is_numeric_type(t_dtype) and tol:\n",
    "        if tol.get(\"type\") == \"abs\":\n",
    "            cond = F.abs(s_col.cast(\"double\") - t_col.cast(\"double\")) > F.lit(float(tol[\"value\"]))\n",
    "        elif tol.get(\"type\") == \"rel\":\n",
    "            cond = F.abs(s_col.cast(\"double\") - t_col.cast(\"double\")) > F.abs(t_col.cast(\"double\") * F.lit(float(tol[\"value\"])))\n",
    "        else:\n",
    "            cond = s_col.cast(\"double\") != t_col.cast(\"double\")\n",
    "    elif is_numeric_type(s_dtype) and is_numeric_type(t_dtype):\n",
    "        cond = s_col.cast(\"double\") != t_col.cast(\"double\")\n",
    "    else:\n",
    "        # String-like default normalization, but if both are timestamps/dates, compare direct\n",
    "        if isinstance(s_dtype, (T.TimestampType, T.DateType)) and isinstance(t_dtype, (T.TimestampType, T.DateType)):\n",
    "            cond = s_col != t_col\n",
    "        else:\n",
    "            cond = normalize_string(f\"s.{src_col}\") != normalize_string(f\"t.{tgt_col}\")\n",
    "\n",
    "    mismatch_conditions.append(cond)\n",
    "\n",
    "    diffs_c = joined.filter(cond).select(\n",
    "        *[F.col(f\"s.{k}\").alias(k) for k in KEY_SRC]\n",
    "    ).select(\n",
    "        F.lit(RUN_ID).alias(\"run_id\"),\n",
    "        F.lit(\"VALUE_MISMATCH\").alias(\"diff_type\"),\n",
    "        json_obj_from_cols(\"\", KEY_SRC).alias(\"key_src_json\"),\n",
    "        json_obj_from_cols(\"\", KEY_SRC).alias(\"key_tgt_json\"),\n",
    "        F.lit(\",\".join(PARTITION_VALUES) if PARTITION_VALUES else None).alias(\"partition_value\"),\n",
    "        F.lit(FILTER_SRC or None).alias(\"filter_source\"),\n",
    "        F.lit(FILTER_TGT or (FILTER_SRC or None)).alias(\"filter_target\"),\n",
    "        F.lit(src_col).alias(\"col_name\"),\n",
    "        F.col(f\"s.{src_col}\").cast(\"string\").alias(\"src_value\"),\n",
    "        F.col(f\"t.{tgt_col}\").cast(\"string\").alias(\"tgt_value\")\n",
    "    )\n",
    "    per_col_diffs.append(diffs_c)\n",
    "\n",
    "mismatch_df = None\n",
    "if per_col_diffs:\n",
    "    mismatch_df = per_col_diffs[0]\n",
    "    for d in per_col_diffs[1:]:\n",
    "        mismatch_df = mismatch_df.unionByName(d)\n",
    "\n",
    "mismatch_rows = joined.filter(reduce(operator.or_, mismatch_conditions)) .select(*[F.col(f\"s.{k}\") for k in KEY_SRC]).distinct().count() if mismatch_conditions else 0\n",
    "\n",
    "summary_rows.append({\n",
    "    \"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE,\n",
    "    \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None,\n",
    "    \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "    \"metric\": \"value_mismatch_rows\", \"metric_value\": float(mismatch_rows),\n",
    "    \"threshold\": float(ALERT_MISMATCH_RATIO_THRESHOLD) * float(max(row_count_src, 1)),\n",
    "    \"status\": \"FAIL\" if mismatch_rows > ALERT_MISMATCH_RATIO_THRESHOLD * max(row_count_src, 1) else (\"WARN\" if mismatch_rows > 0 else \"PASS\"),\n",
    "    \"notes\": f\"Per-column diff records: {mismatch_df.count() if mismatch_df is not None else 0}\"\n",
    "})\n",
    "\n",
    "log_diffs(mismatch_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd7cabdc-c707-426d-b685-c821f15c042c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7) Column Stats Drift (Per-Pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "625b0ae2-6aa2-4622-899d-e9abaa5fad0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "drift_rows = []\n",
    "for src_col, tgt_col in compare_pairs:\n",
    "    s_stats = src_df.select(\n",
    "        F.count(F.col(src_col)).alias(\"cnt\"),\n",
    "        F.count(F.when(F.col(src_col).isNull(), 1)).alias(\"nulls\"),\n",
    "        F.countDistinct(F.col(src_col)).alias(\"distinct\"),\n",
    "        F.min(F.col(src_col)).alias(\"min\"),\n",
    "        F.max(F.col(src_col)).alias(\"max\")\n",
    "    ).first()\n",
    "    t_stats = tgt_df.select(\n",
    "        F.count(F.col(tgt_col)).alias(\"cnt\"),\n",
    "        F.count(F.when(F.col(tgt_col).isNull(), 1)).alias(\"nulls\"),\n",
    "        F.countDistinct(F.col(tgt_col)).alias(\"distinct\"),\n",
    "        F.min(F.col(tgt_col)).alias(\"min\"),\n",
    "        F.max(F.col(tgt_col)).alias(\"max\")\n",
    "    ).first()\n",
    "\n",
    "    drift_rows.extend([\n",
    "        {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE,\n",
    "         \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None, \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "         \"metric\": f\"{src_col}_null_pct_source\", \"metric_value\": float(s_stats[\"nulls\"]) / max(float(s_stats[\"cnt\"]), 1.0), \"threshold\": None, \"status\": \"INFO\", \"notes\": None},\n",
    "        {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE,\n",
    "         \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None, \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "         \"metric\": f\"{tgt_col}_null_pct_target\", \"metric_value\": float(t_stats[\"nulls\"]) / max(float(t_stats[\"cnt\"]), 1.0), \"threshold\": None, \"status\": \"INFO\", \"notes\": None},\n",
    "        {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE,\n",
    "         \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None, \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "         \"metric\": f\"{src_col}_distinct_source\", \"metric_value\": float(int(s_stats[\"distinct\"])), \"threshold\": None, \"status\": \"INFO\", \"notes\": None},\n",
    "        {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE,\n",
    "         \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None, \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "         \"metric\": f\"{tgt_col}_distinct_target\", \"metric_value\": float(int(t_stats[\"distinct\"])), \"threshold\": None, \"status\": \"INFO\", \"notes\": None},\n",
    "        {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE,\n",
    "         \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None, \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "         \"metric\": f\"{src_col}_min_source\", \"metric_value\": float(int(\"0\")), \"threshold\": None, \"status\": \"INFO\", \"notes\": f\"{s_stats['min']}\"},\n",
    "        {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE,\n",
    "         \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None, \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "         \"metric\": f\"{tgt_col}_min_target\", \"metric_value\": float(int(\"0\")), \"threshold\": None, \"status\": \"INFO\", \"notes\": f\"{t_stats['min']}\"},\n",
    "        {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE,\n",
    "         \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None, \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "         \"metric\": f\"{src_col}_max_source\", \"metric_value\": float(int(\"0\")), \"threshold\": None, \"status\": \"INFO\", \"notes\": f\"{s_stats['max']}\"},\n",
    "        {\"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE,\n",
    "         \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None, \"filter_source\": FILTER_SRC or None, \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "         \"metric\": f\"{tgt_col}_max_target\", \"metric_value\": float(int(\"0\")), \"threshold\": None, \"status\": \"INFO\", \"notes\": f\"{t_stats['max']}\"},\n",
    "    ])\n",
    "\n",
    "summary_rows.extend(drift_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33cac918-85fe-4360-b5ce-d784f8af0cfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 8) Canonical Row Hash Check (Based on Compare Pairs)\n",
    "Canonical Row Hash Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d144984-c6f0-4feb-bbf6-4d01ebd6daef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if HASH_CHECK and compare_pairs:\n",
    "    def normalized_concat_side(df, side: str):\n",
    "        exprs = []\n",
    "        for src_col, tgt_col in compare_pairs:\n",
    "            col_name = src_col if side == 's' else tgt_col\n",
    "            dt = next(\n",
    "                (f.dataType for f in (src_df if side == 's' else tgt_df).schema.fields if f.name == col_name),\n",
    "                None\n",
    "            )\n",
    "            c = F.col(col_name)\n",
    "            if isinstance(dt, T.StringType):\n",
    "                c = F.lower(F.trim(c))\n",
    "            exprs.append(c.cast(\"string\"))\n",
    "        return F.sha2(F.concat_ws(\"|\", *exprs), 256)\n",
    "\n",
    "    s_hash = src_df.select(\n",
    "        *[F.col(k).alias(k) for k in KEY_SRC],\n",
    "        normalized_concat_side(src_df, 's').alias(\"row_hash_src\")\n",
    "    )\n",
    "    t_hash = tgt_df.select(\n",
    "        *[F.col(KEY_MAP[k]).alias(k) for k in KEY_SRC],\n",
    "        normalized_concat_side(tgt_df, 't').alias(\"row_hash_tgt\")\n",
    "    )\n",
    "\n",
    "    hash_join = s_hash.join(t_hash, on=KEY_SRC, how=\"inner\")\n",
    "    hash_mismatches = hash_join.filter(F.col(\"row_hash_src\") != F.col(\"row_hash_tgt\")).count()\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"run_id\": RUN_ID, \"run_ts\": None, \"source_table\": SOURCE_TABLE, \"target_table\": TARGET_TABLE,\n",
    "        \"partition_value\": \",\".join(PARTITION_VALUES) if PARTITION_VALUES else None,\n",
    "        \"filter_source\": FILTER_SRC or None,\n",
    "        \"filter_target\": FILTER_TGT or (FILTER_SRC or None),\n",
    "        \"metric\": \"row_hash_mismatches\",\n",
    "        \"metric_value\": float(hash_mismatches),\n",
    "        \"threshold\": float(ALERT_MISMATCH_RATIO_THRESHOLD) * float(max(row_count_src, 1)),\n",
    "        \"status\": \"FAIL\" if hash_mismatches > ALERT_MISMATCH_RATIO_THRESHOLD * max(row_count_src, 1)\n",
    "                  else (\"WARN\" if hash_mismatches > 0 else \"PASS\"),\n",
    "        \"notes\": None\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07a3dc68-4a33-4f45-80d1-6cc28c52d637",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 9) Write Summary & Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74fdd8ec-6342-4ee0-90e3-798fbfdffb3f",
     "showTitle": false,
     "tableResultSettingsMap": {
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"diff_type\":218},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1766779891484}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add timestamps and persist\n",
    "summary_rows = [dict(r, run_ts=datetime.now()) for r in summary_rows]\n",
    "log_summary(summary_rows)\n",
    "\n",
    "try:\n",
    "    display(spark.table(f\"{CATALOG_NAME}.{AUDIT_DB}.audit_results\").filter(F.col(\"run_id\") == RUN_ID))\n",
    "except Exception:\n",
    "    spark.table(f\"{CATALOG_NAME}.{AUDIT_DB}.audit_results\").filter(F.col(\"run_id\") == RUN_ID).show(100, False)\n",
    "\n",
    "try:\n",
    "    display(spark.table(f\"{CATALOG_NAME}.{AUDIT_DB}.audit_diffs\").filter(F.col(\"run_id\") == RUN_ID).limit(100))\n",
    "except Exception:\n",
    "    spark.table(f\"{CATALOG_NAME}.{AUDIT_DB}.audit_diffs\").filter(F.col(\"run_id\") == RUN_ID).show(100, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aba2dcae-0672-42a1-bda3-a0a07b949d28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 10) Threshold Enforcement (Optional Job Fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f4b51c5-c5a5-4d8b-9ad2-2b791a37950c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Test2: FAIL=1, WARN=0\n"
     ]
    }
   ],
   "source": [
    "latest_summary = spark.table(f\"{CATALOG_NAME}.{AUDIT_DB}.audit_results\").filter(F.col(\"run_id\") == RUN_ID).collect()\n",
    "fail_metrics = [r for r in latest_summary if r[\"status\"] == \"FAIL\"]\n",
    "warn_metrics = [r for r in latest_summary if r[\"status\"] == \"WARN\"]\n",
    "\n",
    "status_msg = f\"Run {RUN_ID}: FAIL={len(fail_metrics)}, WARN={len(warn_metrics)}\"\n",
    "print(status_msg)\n",
    "\n",
    "if FAIL_ON_BREACH and len(fail_metrics) > 0:\n",
    "    raise Exception(f\"Audit thresholds breached: {status_msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc88edd2-cf48-4445-8f4e-9a5ba2ad584f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Notes & Examples\n",
    "\n",
    "**Key mapping (JSON)**\n",
    "```json\n",
    "{\"order_id\":\"id\",\"tenant_id\":\"tenant\"}\n",
    "```\n",
    "or use paired lists (same length):\n",
    "\n",
    "- `key_columns_source = order_id,tenant_id`\n",
    "- `key_columns_target = id,tenant`\n",
    "\n",
    "**Compare mapping (JSON)** (for differing names):\n",
    "```json\n",
    "{\"amount\":\"amt\",\"status\":\"state\"}\n",
    "```\n",
    "If omitted, same-name columns (excluding keys/excludes) are auto-compared.\n",
    "\n",
    "**Tolerances (JSON)** â€” key by **source** or **target** column name:\n",
    "```json\n",
    "{\"amount\": {\"type\": \"abs\", \"value\": 0.01}, \"rate\": {\"type\": \"rel\", \"value\": 0.001}}\n",
    "```\n",
    "\n",
    "**Filters** use Spark SQL expressions:\n",
    "- `filter_condition_source = status = 'ACTIVE' AND amount > 0 AND order_date >= '2025-12-01'`\n",
    "- `filter_condition_target =` *(leave blank to reuse source filter)*\n",
    "\n",
    "**Partitions** are applied before filters if provided.\n",
    "\n",
    "**Audit tables**: `{CATALOG_NAME}.{AUDIT_DB}.audit_results` and `{CATALOG_NAME}.{AUDIT_DB}.audit_diffs`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36bf9153-b353-4a72-9961-d474ff4de00c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Notes\n",
    "- You can use **partition filters** *and/or* **custom filter conditions**. If `filter_condition_target` is blank, the source filter is applied to the target.\n",
    "- Filters use Spark SQL expressions (e.g., `status = \"ACTIVE\" AND amount > 0 AND order_date >= '2025-12-01'`).\n",
    "- Unity Catalog FQNs recommended: `catalog.schema.table`.\n",
    "- Summary & diffs are stored in `{CATALOG_NAME}.{AUDIT_DB}.audit_results` and `{CATALOG_NAME}.{AUDIT_DB}.audit_diffs` (Delta tables).\n",
    "- Hook this notebook in a Databricks Job; pass widget parameters per table pair.\n",
    "\n",
    "### Example Parameters\n",
    "- `source_table = prod.analytics.orders`  \n",
    "- `target_table = curated.analytics.orders_clean`  \n",
    "- `key_columns = order_id`  \n",
    "- `exclude_columns = _ingest_ts,_load_id`  \n",
    "- `filter_condition_source = status = \"ACTIVE\" AND amount > 0`  \n",
    "- `filter_condition_target =` *(blank to reuse source filter)*  \n",
    "- `tolerance_map_json = {\"amount\": {\"type\":\"abs\", \"value\":0.01}}`  \n",
    "- `hash_check = true`  \n",
    "- `alert_missing_row_threshold = 0`  \n",
    "- `alert_mismatch_ratio_threshold = 0.001`  \n",
    "- `fail_on_threshold_breach = false`  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5806505195727506,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Audit process 2",
   "widgets": {
    "alert_mismatch_ratio_threshold": {
     "currentValue": "0.001",
     "nuid": "1e7a99e4-deb8-4c67-bddb-157a37ccd203",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "0.001",
      "label": null,
      "name": "alert_mismatch_ratio_threshold",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "0.001",
      "label": null,
      "name": "alert_mismatch_ratio_threshold",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "alert_missing_row_threshold": {
     "currentValue": "0",
     "nuid": "343ad4aa-a93e-4470-b547-1537343b2618",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "0",
      "label": null,
      "name": "alert_missing_row_threshold",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "0",
      "label": null,
      "name": "alert_missing_row_threshold",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "audit_database": {
     "currentValue": "_sandbox_dev",
     "nuid": "17d49652-3f60-4d51-b71c-751ca585a091",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "_sandbox_dev",
      "label": null,
      "name": "audit_database",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "_sandbox_dev",
      "label": null,
      "name": "audit_database",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "catalog": {
     "currentValue": "kr_payment_nonprod",
     "nuid": "97f7cf00-3432-45af-9edc-6a0c4ea823a3",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "kr_payment_nonprod",
      "label": null,
      "name": "catalog",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "kr_payment_nonprod",
      "label": null,
      "name": "catalog",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "compare_map_json": {
     "currentValue": "{}",
     "nuid": "2f7f93b6-542a-4f30-bc5d-5cbfe0421941",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "{}",
      "label": null,
      "name": "compare_map_json",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "{}",
      "label": null,
      "name": "compare_map_json",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "exclude_columns_source": {
     "currentValue": "",
     "nuid": "24b48001-fbb9-4203-a79c-e5e8fe3055d2",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "_ingest_ts,_load_id",
      "label": null,
      "name": "exclude_columns_source",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "_ingest_ts,_load_id",
      "label": null,
      "name": "exclude_columns_source",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "exclude_columns_target": {
     "currentValue": "",
     "nuid": "46aff95c-d97a-4570-8cc9-1dc5884a6927",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "_ingest_ts,_load_id",
      "label": null,
      "name": "exclude_columns_target",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "_ingest_ts,_load_id",
      "label": null,
      "name": "exclude_columns_target",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "fail_on_threshold_breach": {
     "currentValue": "false",
     "nuid": "0498e39b-a31b-49ec-ba6e-1121aa7b023f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "false",
      "label": "fail_on_threshold_breach",
      "name": "fail_on_threshold_breach",
      "options": {
       "choices": [
        "true",
        "false"
       ],
       "fixedDomain": true,
       "multiselect": false,
       "widgetDisplayType": "Dropdown"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "false",
      "label": "fail_on_threshold_breach",
      "name": "fail_on_threshold_breach",
      "options": {
       "autoCreated": null,
       "choices": [
        "true",
        "false"
       ],
       "widgetType": "dropdown"
      },
      "widgetType": "dropdown"
     }
    },
    "filter_condition_source": {
     "currentValue": "",
     "nuid": "71940687-86e0-410e-8d00-4a6c7dea8d98",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "filter_condition_source",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "filter_condition_source",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "filter_condition_target": {
     "currentValue": "",
     "nuid": "1a06028c-edf8-456f-bdd1-79e2b15a935a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "filter_condition_target",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "filter_condition_target",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "hash_check": {
     "currentValue": "true",
     "nuid": "34db680b-6c1c-49b1-bcab-b2655a57bfda",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "true",
      "label": "hash_check",
      "name": "hash_check",
      "options": {
       "choices": [
        "true",
        "false"
       ],
       "fixedDomain": true,
       "multiselect": false,
       "widgetDisplayType": "Dropdown"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "true",
      "label": "hash_check",
      "name": "hash_check",
      "options": {
       "autoCreated": null,
       "choices": [
        "true",
        "false"
       ],
       "widgetType": "dropdown"
      },
      "widgetType": "dropdown"
     }
    },
    "key_columns_source": {
     "currentValue": "Transaction_Number",
     "nuid": "6953e4a8-db18-43d7-b452-f677e0053d2b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "key_columns_source",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "key_columns_source",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "key_columns_target": {
     "currentValue": "Transaction_Number",
     "nuid": "3066f515-0f11-44bd-88e3-f55ef826ebcc",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "key_columns_target",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "key_columns_target",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "key_map_json": {
     "currentValue": "{}",
     "nuid": "73f68859-71f7-4bdc-becb-c5f37d89951c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "{}",
      "label": null,
      "name": "key_map_json",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "{}",
      "label": null,
      "name": "key_map_json",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "partition_column": {
     "currentValue": "",
     "nuid": "b4c4608e-a43f-44f9-b5bc-f2a6f8ee2cd7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "partition_column",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "partition_column",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "partition_values": {
     "currentValue": "",
     "nuid": "b62b3c75-f985-4f7e-b4f5-17fc4858e7f3",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "partition_values",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "partition_values",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "run_id": {
     "currentValue": "Test2",
     "nuid": "ff4d99cd-7d38-4b81-9c8f-d0b8dc98065e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "run_id",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "run_id",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "source_table": {
     "currentValue": "kr_payment_nonprod.tlog_dev.tlog_check_declines_stg",
     "nuid": "6fd74154-bb1c-4f45-85c3-f826996c0886",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "kr_payment_nonprod.tlog_dev.tlog_check_declines_stg",
      "label": null,
      "name": "source_table",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "kr_payment_nonprod.tlog_dev.tlog_check_declines_stg",
      "label": null,
      "name": "source_table",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "target_table": {
     "currentValue": "kr_payment_nonprod.tlog_dev.tlog_check_declines_data",
     "nuid": "77cf0747-78fb-4298-a23e-03f4f709d7e8",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "kr_payment_nonprod.tlog_dev.tlog_check_declines_data",
      "label": null,
      "name": "target_table",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "kr_payment_nonprod.tlog_dev.tlog_check_declines_data",
      "label": null,
      "name": "target_table",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "tolerance_map_json": {
     "currentValue": "{}",
     "nuid": "90e40e44-8ded-4642-bdd4-58bc7c2e1522",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "{}",
      "label": null,
      "name": "tolerance_map_json",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "{}",
      "label": null,
      "name": "tolerance_map_json",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
